{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import scipy.sparse as sp\n",
    "import sklearn.preprocessing as sk\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, normalize\n",
    "import cosine_similarity\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cosine_Similarity:\n",
    "\n",
    "    def __init__(self, dataMatrix, topK=100, shrink = 0, normalize = True,\n",
    "                 mode = \"cosine\"):\n",
    "        \"\"\"\n",
    "        Computes the cosine similarity on the columns of dataMatrix\n",
    "        If it is computed on URM=|users|x|items|, pass the URM as is.\n",
    "        If it is computed on ICM=|items|x|features|, pass the ICM transposed.\n",
    "        :param dataMatrix:\n",
    "        :param topK:\n",
    "        :param shrink:\n",
    "        :param normalize:\n",
    "        :param mode:    \"cosine\"    computes Cosine similarity\n",
    "                        \"adjusted\"  computes Adjusted Cosine, removing the average of the users\n",
    "                        \"pearson\"   computes Pearson Correlation, removing the average of the items\n",
    "                        \"jaccard\"   computes Jaccard similarity for binary interactions using Tanimoto\n",
    "                        \"tanimoto\"  computes Tanimoto coefficient for binary interactions\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        super(Cosine_Similarity, self).__init__()\n",
    "\n",
    "        self.TopK = topK\n",
    "        self.shrink = shrink\n",
    "        self.normalize = normalize\n",
    "        self.n_columns = dataMatrix.shape[1]\n",
    "        self.n_rows = dataMatrix.shape[0]\n",
    "\n",
    "        self.dataMatrix = dataMatrix.copy()\n",
    "\n",
    "        self.adjusted_cosine = False\n",
    "        self.pearson_correlation = False\n",
    "        self.tanimoto_coefficient = False\n",
    "\n",
    "        if mode == \"adjusted\":\n",
    "            self.adjusted_cosine = True\n",
    "        elif mode == \"pearson\":\n",
    "            self.pearson_correlation = True\n",
    "        elif mode == \"jaccard\" or mode == \"tanimoto\":\n",
    "            self.tanimoto_coefficient = True\n",
    "            # Tanimoto has a specific kind of normalization\n",
    "            self.normalize = False\n",
    "\n",
    "        elif mode == \"cosine\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"Cosine_Similarity: value for paramether 'mode' not recognized.\"\n",
    "                             \" Allowed values are: 'cosine', 'pearson', 'adjusted', 'jaccard', 'tanimoto'.\"\n",
    "                             \" Passed value was '{}'\".format(mode))\n",
    "\n",
    "\n",
    "\n",
    "        if self.TopK == 0:\n",
    "            self.W_dense = np.zeros((self.n_columns, self.n_columns))\n",
    "\n",
    "\n",
    "    def check_matrix(self, X, format='csc', dtype=np.float32):\n",
    "        if format == 'csc' and not isinstance(X, sp.csc_matrix):\n",
    "            return X.tocsc().astype(dtype)\n",
    "        elif format == 'csr' and not isinstance(X, sp.csr_matrix):\n",
    "            return X.tocsr().astype(dtype)\n",
    "        elif format == 'coo' and not isinstance(X, sp.coo_matrix):\n",
    "            return X.tocoo().astype(dtype)\n",
    "        elif format == 'dok' and not isinstance(X, sp.dok_matrix):\n",
    "            return X.todok().astype(dtype)\n",
    "        elif format == 'bsr' and not isinstance(X, sp.bsr_matrix):\n",
    "            return X.tobsr().astype(dtype)\n",
    "        elif format == 'dia' and not isinstance(X, sp.dia_matrix):\n",
    "            return X.todia().astype(dtype)\n",
    "        elif format == 'lil' and not isinstance(X, sp.lil_matrix):\n",
    "            return X.tolil().astype(dtype)\n",
    "        else:\n",
    "            return X.astype(dtype)\n",
    "\n",
    "\n",
    "    def applyAdjustedCosine(self):\n",
    "        \"\"\"\n",
    "        Remove from every data point the average for the corresponding row\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataMatrix = self.check_matrix(self.dataMatrix, 'csr')\n",
    "\n",
    "\n",
    "        interactionsPerRow = np.diff(self.dataMatrix.indptr)\n",
    "\n",
    "        nonzeroRows = interactionsPerRow > 0\n",
    "        sumPerRow = np.asarray(self.dataMatrix.sum(axis=1)).ravel()\n",
    "\n",
    "        rowAverage = np.zeros_like(sumPerRow)\n",
    "        rowAverage[nonzeroRows] = sumPerRow[nonzeroRows] / interactionsPerRow[nonzeroRows]\n",
    "\n",
    "\n",
    "        # Split in blocks to avoid duplicating the whole data structure\n",
    "        start_row = 0\n",
    "        end_row= 0\n",
    "\n",
    "        blockSize = 1000\n",
    "\n",
    "\n",
    "        while end_row < self.n_rows:\n",
    "\n",
    "            end_row = min(self.n_rows, end_row + blockSize)\n",
    "\n",
    "            self.dataMatrix.data[self.dataMatrix.indptr[start_row]:self.dataMatrix.indptr[end_row]] -= \\\n",
    "                np.repeat(rowAverage[start_row:end_row], interactionsPerRow[start_row:end_row])\n",
    "\n",
    "            start_row += blockSize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def applyPearsonCorrelation(self):\n",
    "        \"\"\"\n",
    "        Remove from every data point the average for the corresponding column\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataMatrix = self.check_matrix(self.dataMatrix, 'csc')\n",
    "\n",
    "\n",
    "        interactionsPerCol = np.diff(self.dataMatrix.indptr)\n",
    "\n",
    "        nonzeroCols = interactionsPerCol > 0\n",
    "        sumPerCol = np.asarray(self.dataMatrix.sum(axis=0)).ravel()\n",
    "\n",
    "        colAverage = np.zeros_like(sumPerCol)\n",
    "        colAverage[nonzeroCols] = sumPerCol[nonzeroCols] / interactionsPerCol[nonzeroCols]\n",
    "\n",
    "\n",
    "        # Split in blocks to avoid duplicating the whole data structure\n",
    "        start_col = 0\n",
    "        end_col= 0\n",
    "\n",
    "        blockSize = 1000\n",
    "\n",
    "\n",
    "        while end_col < self.n_columns:\n",
    "\n",
    "            end_col = min(self.n_columns, end_col + blockSize)\n",
    "\n",
    "            self.dataMatrix.data[self.dataMatrix.indptr[start_col]:self.dataMatrix.indptr[end_col]] -= \\\n",
    "                np.repeat(colAverage[start_col:end_col], interactionsPerCol[start_col:end_col])\n",
    "\n",
    "            start_col += blockSize\n",
    "\n",
    "\n",
    "    def useOnlyBooleanInteractions(self):\n",
    "\n",
    "        # Split in blocks to avoid duplicating the whole data structure\n",
    "        start_pos = 0\n",
    "        end_pos= 0\n",
    "\n",
    "        blockSize = 1000\n",
    "\n",
    "\n",
    "        while end_pos < len(self.dataMatrix.data):\n",
    "\n",
    "            end_pos = min(len(self.dataMatrix.data), end_pos + blockSize)\n",
    "\n",
    "            self.dataMatrix.data[start_pos:end_pos] = np.ones(end_pos-start_pos)\n",
    "\n",
    "            start_pos += blockSize\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def compute_similarity(self):\n",
    "\n",
    "        values = []\n",
    "        rows = []\n",
    "        cols = []\n",
    "\n",
    "        start_time = time.time()\n",
    "        start_time_print_batch = start_time\n",
    "        processedItems = 0\n",
    "\n",
    "        if self.adjusted_cosine:\n",
    "            self.applyAdjustedCosine()\n",
    "\n",
    "        elif self.pearson_correlation:\n",
    "            self.applyPearsonCorrelation()\n",
    "\n",
    "        elif self.tanimoto_coefficient:\n",
    "            self.useOnlyBooleanInteractions()\n",
    "\n",
    "\n",
    "        # We explore the matrix column-wise\n",
    "        self.dataMatrix = self.check_matrix(self.dataMatrix, 'csc')\n",
    "\n",
    "\n",
    "        # Compute sum of squared values to be used in normalization\n",
    "        sumOfSquared = np.array(self.dataMatrix.power(2).sum(axis=0)).ravel()\n",
    "\n",
    "        # Tanimoto does not require the square root to be applied\n",
    "        if not self.tanimoto_coefficient:\n",
    "            sumOfSquared = np.sqrt(sumOfSquared)\n",
    "\n",
    "\n",
    "        # Compute all similarities for each item using vectorization\n",
    "        for columnIndex in range(self.n_columns):\n",
    "\n",
    "            processedItems += 1\n",
    "\n",
    "            if time.time() - start_time_print_batch >= 30 or processedItems==self.n_columns:\n",
    "                columnPerSec = processedItems / (time.time() - start_time)\n",
    "\n",
    "                print(\"Similarity column {} ( {:2.0f} % ), {:.2f} column/sec, elapsed time {:.2f} min\".format(\n",
    "                    processedItems, processedItems / self.n_columns * 100, columnPerSec, (time.time() - start_time)/ 60))\n",
    "\n",
    "                sys.stdout.flush()\n",
    "                sys.stderr.flush()\n",
    "\n",
    "                start_time_print_batch = time.time()\n",
    "\n",
    "\n",
    "            # All data points for a given item\n",
    "            item_data = self.dataMatrix[:, columnIndex]\n",
    "            item_data = item_data.toarray().squeeze()\n",
    "\n",
    "            # Compute item similarities\n",
    "            this_column_weights = self.dataMatrix.T.dot(item_data)\n",
    "            this_column_weights[columnIndex] = 0.0\n",
    "\n",
    "            # Apply normalization and shrinkage, ensure denominator != 0\n",
    "            if self.normalize:\n",
    "                denominator = sumOfSquared[columnIndex] * sumOfSquared + self.shrink + 1e-6\n",
    "                this_column_weights = np.multiply(this_column_weights, 1 / denominator)\n",
    "\n",
    "            # Apply the specific denominator for Tanimoto\n",
    "            elif self.tanimoto_coefficient:\n",
    "                denominator = sumOfSquared[columnIndex] + sumOfSquared - this_column_weights + self.shrink + 1e-6\n",
    "                this_column_weights = np.multiply(this_column_weights, 1 / denominator)\n",
    "\n",
    "            # If no normalization or tanimoto is selected, apply only shrink\n",
    "            elif self.shrink != 0:\n",
    "                this_column_weights = this_column_weights/self.shrink\n",
    "\n",
    "\n",
    "            if self.TopK == 0:\n",
    "                self.W_dense[:, columnIndex] = this_column_weights\n",
    "\n",
    "            else:\n",
    "                # Sort indices and select TopK\n",
    "                # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "                # - Partition the data to extract the set of relevant items\n",
    "                # - Sort only the relevant items\n",
    "                # - Get the original item index\n",
    "                relevant_items_partition = (-this_column_weights).argpartition(self.TopK-1)[0:self.TopK]\n",
    "                relevant_items_partition_sorting = np.argsort(-this_column_weights[relevant_items_partition])\n",
    "                top_k_idx = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "                # Incrementally build sparse matrix\n",
    "                values.extend(this_column_weights[top_k_idx])\n",
    "                rows.extend(top_k_idx)\n",
    "                cols.extend(np.ones(self.TopK) * columnIndex)\n",
    "\n",
    "        if self.TopK == 0:\n",
    "            return self.W_dense\n",
    "\n",
    "        else:\n",
    "\n",
    "            W_sparse = sp.csr_matrix((values, (rows, cols)),\n",
    "                                      shape=(self.n_columns, self.n_columns),\n",
    "                                      dtype=np.float32)\n",
    "\n",
    "\n",
    "            return W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Utils(object):\n",
    "\n",
    "    def __init__(self, train, tracks, target_playlists):\n",
    "        self.train = train\n",
    "        self.tracks = tracks\n",
    "        self.target_playlists = target_playlists\n",
    "\n",
    "    def get_target_playlists(self):\n",
    "        return self.target_playlists\n",
    "\n",
    "    @staticmethod\n",
    "    def get_top10_tracks(URM, my_id, row):\n",
    "        my_indices = URM.indices[URM.indptr[my_id]:URM.indptr[my_id + 1]]\n",
    "        target_indices = list(np.intersect1d(row.indices, my_indices))\n",
    "        row[0, target_indices] = 0\n",
    "        row.eliminate_zeros()\n",
    "        top10_tracks = row.toarray().flatten().argsort()[-10:][::-1]\n",
    "        return top10_tracks\n",
    "\n",
    "    def get_URM(self):\n",
    "        grouped = self.train.groupby('playlist_id', as_index=True).apply((lambda playlist: list(playlist['track_id'])))\n",
    "        URM = MultiLabelBinarizer(classes=self.tracks['track_id'].unique(), sparse_output=True).fit_transform(grouped)\n",
    "        return URM\n",
    "\n",
    "    def get_UCM(self, URM):\n",
    "        UCM = TfidfTransformer().fit_transform(URM.T).T\n",
    "        return normalize(UCM, 'l2', 0).tocsr()\n",
    "\n",
    "    def get_ICM(self):  # returns Item Content Matrix\n",
    "        grouped = self.tracks.groupby('track_id', as_index=True).apply((lambda track: list(track['artist_id'])))\n",
    "\n",
    "        ICM_artists = MultiLabelBinarizer(classes=self.tracks['artist_id'].unique(), sparse_output=True).fit_transform(\n",
    "            grouped)\n",
    "        ICM_artists = ICM_artists * 0.8  # best weight for the artis feature\n",
    "        ICM_artists = TfidfTransformer().fit_transform(ICM_artists.T).T\n",
    "\n",
    "        grouped = self.tracks.groupby('track_id', as_index=True).apply((lambda track: list(track['album_id'])))\n",
    "        ICM_albums = MultiLabelBinarizer(classes=self.tracks['album_id'].unique(), sparse_output=True).fit_transform(\n",
    "            grouped)\n",
    "        ICM_albums = TfidfTransformer().fit_transform(ICM_albums.T).T\n",
    "\n",
    "        ICM = sp.hstack((ICM_artists, ICM_albums))\n",
    "        return normalize(ICM, 'l2', 0).tocsr()\n",
    "\n",
    "    def get_itemsim_CB(self, knn, shrink, mode):\n",
    "        ICM = self.get_ICM()\n",
    "\n",
    "        similarity = Cosine_Similarity(dataMatrix=ICM.T, normalize=True, shrink=shrink, mode=mode,\n",
    "                                                         topK = knn)\n",
    "        S = similarity.compute_similarity()\n",
    "\n",
    "        return S.tocsr()\n",
    "\n",
    "    def get_itemsim_CF(self, URM, knn, shrink, mode):\n",
    "        UCM = self.get_UCM(URM)\n",
    "\n",
    "        similarity = Cosine_Similarity(dataMatrix=UCM, normalize=True, shrink=shrink, mode=mode,\n",
    "                                                         topK = knn)\n",
    "        S = similarity.compute_similarity()\n",
    "\n",
    "        return S.tocsr()\n",
    "\n",
    "    def get_usersim_CF(self, URM, knn, shrink, mode):\n",
    "        UCM = self.get_UCM(URM)\n",
    "\n",
    "        similarity = Cosine_Similarity(dataMatrix=UCM.T, normalize=True, shrink=shrink, mode=mode,\n",
    "                                                         topK = knn)\n",
    "        S = similarity.compute_similarity()\n",
    "\n",
    "        return S.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class Eval(object):\n",
    "\n",
    "    def __init__(self, u):\n",
    "        self.URM = u.get_URM()\n",
    "        self.target_playlists = None\n",
    "        self.target_tracks = None\n",
    "        self.URM_train = None\n",
    "        self.build_URM_test()\n",
    "\n",
    "    def build_URM_test(self):\n",
    "        total_users = self.URM.shape[0]\n",
    "        self.URM_train = self.URM.copy().tolil()\n",
    "        possibile_playlists = [i for i in range(total_users) if len(\n",
    "            self.URM.indices[self.URM.indptr[i]:self.URM.indptr[i + 1]]) > 10]  # playlists with more than 10 songs\n",
    "\n",
    "        self.target_playlists = pd.DataFrame(data=random.sample(possibile_playlists, int(0.20 * total_users)),\n",
    "                                             columns=['playlist_id'])  # target playlists, 20% of total playlists\n",
    "        self.target_tracks = []\n",
    "\n",
    "        for idx in list(self.target_playlists['playlist_id']):\n",
    "            target_songs = random.sample(list(self.URM.indices[self.URM.indptr[idx]:self.URM.indptr[idx + 1]]), 10)\n",
    "            self.URM_train[idx, target_songs] = 0\n",
    "            self.target_tracks.append(target_songs)\n",
    "\n",
    "        self.target_tracks = np.array(self.target_tracks)\n",
    "        self.URM_train = self.URM_train.tocsr()\n",
    "\n",
    "    def get_URM_train(self):\n",
    "        return self.URM_train\n",
    "\n",
    "    def get_URM(self):\n",
    "        return self.URM\n",
    "\n",
    "    def get_target_playlists(self):\n",
    "        return self.target_playlists\n",
    "\n",
    "    def get_target_tracks(self):\n",
    "        return self.target_tracks\n",
    "\n",
    "    @staticmethod\n",
    "    def AP(recommended_items, relevant_items):\n",
    "        relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "        p_at_k = relevant * np.cumsum(relevant, dtype=np.float32) / (1 + np.arange(relevant.shape[0]))\n",
    "        map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], relevant.shape[0]])\n",
    "        return map_score\n",
    "\n",
    "    # input has to be the URM and the dataframe returned by the recommender\n",
    "    # NB: the songs in the dataframe must be a list (or ndarray), not a string!\n",
    "    def MAP(self, df, relevant_items):\n",
    "        print(\"Evaluating\", flush=True)\n",
    "        MAP = 0.0\n",
    "        num_eval = 0\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            relevant = relevant_items[i]\n",
    "            if len(relevant_items) > 0:\n",
    "                recommended_items = df['track_ids'][i]\n",
    "                num_eval += 1\n",
    "                MAP += self.AP(recommended_items, relevant)\n",
    "\n",
    "        MAP /= num_eval\n",
    "        print(\"Recommender performance is {:.8f}\".format(MAP))\n",
    "\n",
    "    def result_diff(self, result_dfs):\n",
    "\n",
    "        # load  all results form various recommenders\n",
    "        # for file in files:\n",
    "        #   results.append(pd.read_csv(file))\n",
    "\n",
    "        for i, result in enumerate(result_dfs):\n",
    "            for j, result_2 in enumerate(result_dfs):\n",
    "                tot_diff = 0\n",
    "                for row, row_2 in zip(result['track_ids'], result_2['track_ids']):\n",
    "                    row, row_2 = list(row), list(row_2)\n",
    "                    row = [el for el in row if el != ' ']\n",
    "                    row_2 = [el for el in row_2 if el != ' ']\n",
    "                    tot_diff += [1 for x, y in zip(row, row_2) if x != y].count(1)\n",
    "                print('Total differences between res %d and res %d are: %d' % (i, j, tot_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eval2(object): #this is the version no bias, to be fixed\n",
    "\n",
    "    def __init__(self, u):\n",
    "        self.URM = u.get_URM()\n",
    "        self.URM_train = None\n",
    "        self.URM_test = None\n",
    "        self.target_playlists = None\n",
    "        self.build_URM()\n",
    "\n",
    "    def build_URM(self):\n",
    "        itemList = self.URM.indices\n",
    "        ratingList = self.URM.data\n",
    "        userList = []\n",
    "\n",
    "        for i in range(self.URM.shape[0]):\n",
    "            userList.extend(len(self.URM.indices[self.URM.indptr[i]:self.URM.indptr[i+1]])*[i])\n",
    "\n",
    "        train_test_split = 0.80\n",
    "        numInteractions = self.URM.nnz\n",
    "\n",
    "        train_mask = np.random.choice([True,False], numInteractions, p = [train_test_split, 1-train_test_split])\n",
    "        test_mask = np.logical_not(train_mask)\n",
    "\n",
    "        userList = np.array(userList)\n",
    "        itemList = np.array(itemList)\n",
    "        ratingList = np.array(ratingList)\n",
    "\n",
    "        self.URM_train = sp.coo_matrix((ratingList[train_mask], (userList[train_mask], itemList[train_mask])), shape = self.URM.shape)\n",
    "        self.URM_train = self.URM_train.tocsr()\n",
    "        \n",
    "        self.URM_test = sp.coo_matrix((ratingList[test_mask], (userList[test_mask], itemList[test_mask])), shape = self.URM.shape)\n",
    "        self.URM_test = self.URM_test.tocsr()\n",
    "        \n",
    "        self.target_playlists = np.random.choice(np.unique(userList[test_mask]),10000, replace = False)\n",
    "        \n",
    "\n",
    "    def get_URM_test(self):\n",
    "        return self.URM_test\n",
    "\n",
    "    def get_URM_train(self):\n",
    "        return self.URM_train\n",
    "\n",
    "    def get_target_playlists(self):\n",
    "        return self.target_playlists\n",
    "\n",
    "    def AP(self, recommended_items, relevant_items):\n",
    "        relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
    "        p_at_k = relevant * np.cumsum(relevant, dtype=np.float32) / (1 + np.arange(relevant.shape[0]))\n",
    "        map_score = np.sum(p_at_k) / np.min([relevant_items.shape[0], relevant.shape[0]])\n",
    "        return map_score\n",
    "\n",
    "    # input has to be the URM and the dataframe returned by the recommender\n",
    "    # NB: the songs in the dataframe must be a list (or ndarray), not a string!\n",
    "    def MAP(self, df):\n",
    "        print(\"Evaluating\", flush = True)\n",
    "        MAP = 0.0\n",
    "        num_eval = 0\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            current = df['playlist_id'][i]\n",
    "            relevant = self.URM_test[current].indices\n",
    "            if len(relevant) > 0:\n",
    "                recommended_items = df['track_ids'][i]\n",
    "                num_eval += 1\n",
    "                MAP += self.AP(recommended_items, relevant)\n",
    "\n",
    "        MAP /= num_eval\n",
    "        print(\"Recommender performance is {:.8f}\".format(MAP))\n",
    "        \n",
    "        \n",
    "    def result_diff(self, result_dfs):\n",
    "\n",
    "    #load  all results form various recommenders\n",
    "    #for file in files:\n",
    "    #   results.append(pd.read_csv(file))\n",
    "    \n",
    "        for i, result in enumerate(result_dfs):\n",
    "            for j, result_2 in enumerate(result_dfs):\n",
    "                tot_diff = 0\n",
    "                for row, row_2 in zip(result['track_ids'], result_2['track_ids']):\n",
    "                    row, row_2 = list(row), list(row_2)\n",
    "                    row = [el for el in row if el != ' ']\n",
    "                    row_2 = [el for el in row_2 if el != ' ']\n",
    "                    tot_diff += [1 for x,y in zip(row,row_2) if x!=y].count(1)\n",
    "                print('Total differences between res %d and res %d are: %d' % (i, j, tot_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlimBPR(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 URM,\n",
    "                 learning_rate=0.01,\n",
    "                 epochs=1,\n",
    "                 positive_item_regularization=1.0,\n",
    "                 negative_item_regularization=1.0,\n",
    "                 nnz=1):\n",
    "        self.URM = URM\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.positive_item_regularization = positive_item_regularization\n",
    "        self.negative_item_regularization = negative_item_regularization\n",
    "        self.nnz = nnz\n",
    "        self.n_playlist = self.URM.shape[0]\n",
    "        self.n_track = self.URM.shape[1]\n",
    "\n",
    "        self.similarity_matrix = sp.lil_matrix((self.n_track, self.n_playlist))\n",
    "\n",
    "    def sample(self):\n",
    "\n",
    "        playlist_id = np.random.choice(self.n_playlist)\n",
    "\n",
    "        # get tracks in playlist and choose one\n",
    "        tracks = self.URM[playlist_id, :].indices\n",
    "        pos_track_id = np.random.choice(tracks)\n",
    "\n",
    "        negTrackSelected = False\n",
    "\n",
    "        while not negTrackSelected:\n",
    "            neg_track_id = np.random.choice(self.n_track)\n",
    "            if neg_track_id not in tracks:\n",
    "                negTrackSelected = True\n",
    "        return playlist_id, pos_track_id, neg_track_id\n",
    "\n",
    "    def epochIteration(self):\n",
    "\n",
    "        numPosInteractions = int(self.URM.nnz * self.nnz)\n",
    "\n",
    "        # sampling without replacement\n",
    "        # tqdm performs range op with progress visualization\n",
    "        for num_sample in tqdm(range(numPosInteractions)):\n",
    "\n",
    "            playlist_id, pos_track_id, neg_track_id = self.sample()\n",
    "\n",
    "            tracks = self.URM[playlist_id, :].indices\n",
    "\n",
    "            # Prediction\n",
    "            x_i = self.similarity_matrix[pos_track_id, tracks].sum()\n",
    "            x_j = self.similarity_matrix[neg_track_id, tracks].sum()\n",
    "\n",
    "            # Gradient\n",
    "            x_ij = x_i - x_j\n",
    "\n",
    "            gradient = 1 / (1 + np.exp(x_ij))\n",
    "\n",
    "            for i in tracks:\n",
    "                # dp and dn outside for?\n",
    "                dp = gradient - self.positive_item_regularization * x_i\n",
    "                self.similarity_matrix[pos_track_id, i] = self.similarity_matrix[\n",
    "                                                              pos_track_id, i] + self.learning_rate * dp\n",
    "                dn = gradient - self.negative_item_regularization * x_j\n",
    "                self.similarity_matrix[neg_track_id, i] = self.similarity_matrix[\n",
    "                                                              neg_track_id, i] - self.learning_rate * dn\n",
    "\n",
    "            self.similarity_matrix[pos_track_id, pos_track_id] = 0\n",
    "            self.similarity_matrix[pos_track_id, pos_track_id] = 0\n",
    "\n",
    "    def get_S_SLIM_BPR(self, knn):\n",
    "        print('get S Slim BPR...')\n",
    "\n",
    "        for numEpoch in range(self.epochs):\n",
    "            print('Epoch: ', numEpoch)\n",
    "            self.epochIteration()\n",
    "\n",
    "        # replace with our own knn methods\n",
    "        print('Keeping only knn =', knn, '...')\n",
    "        similarity_matrix_csr = self.similarity_matrix.tocsr()\n",
    "\n",
    "        for row in tqdm(range(0, similarity_matrix_csr.shape[0])):\n",
    "            ordered_indices = similarity_matrix_csr[row, :].data.argsort()[:-knn]\n",
    "            similarity_matrix_csr[row, :].data[ordered_indices] = 0\n",
    "        sp.csr_matrix.eliminate_zeros(similarity_matrix_csr)\n",
    "\n",
    "        return similarity_matrix_csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item_CBR(object):\n",
    "\n",
    "    def __init__(self, u):\n",
    "        self.u = u\n",
    "        self.URM = None\n",
    "        self.target_playlists = None\n",
    "        self.S = None\n",
    "\n",
    "    def fit(self, URM, target_playlists, knn, shrink, mode ):\n",
    "        self.URM = URM\n",
    "        self.target_playlists = target_playlists\n",
    "        self.S = self.u.get_itemsim_CB(knn, shrink, mode)\n",
    "\n",
    "    def recommend(self, is_test):\n",
    "        print(\"Recommending\", flush = True)\n",
    "        final_result = pd.DataFrame(index = range(self.target_playlists.shape[0]), columns=('playlist_id', 'track_ids'))\n",
    "\n",
    "        for i, target_playlist in tqdm(enumerate(np.array(self.target_playlists))):\n",
    "\n",
    "            URM_row = self.URM[target_playlist, :] * self.S\n",
    "\n",
    "            result_tracks = self.u.get_top10_tracks(self.URM, target_playlist[0], URM_row)\n",
    "            string_rec = ' '.join(map(str, result_tracks.reshape(1, 10)[0]))\n",
    "            final_result['playlist_id'][i] = int(target_playlist)\n",
    "            if is_test:\n",
    "                final_result['track_ids'][i] = result_tracks\n",
    "            else:\n",
    "                final_result['track_ids'][i] = string_rec\n",
    "\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item_CFR(object):\n",
    "\n",
    "    def __init__(self, u):\n",
    "        self.u = u\n",
    "        self.URM = None\n",
    "        self.target_playlists = None\n",
    "        self.S = None\n",
    "\n",
    "    def fit(self, URM, target_playlists, knn, shrink, mode):\n",
    "        self.URM = URM\n",
    "        self.target_playlists = target_playlists\n",
    "        self.S = self.u.get_itemsim_CF(self.URM, knn, shrink, mode)\n",
    "\n",
    "    def recommend(self, is_test):\n",
    "        print(\"Recommending\", flush=True)\n",
    "        final_result = pd.DataFrame(index=range(self.target_playlists.shape[0]), columns=('playlist_id', 'track_ids'))\n",
    "\n",
    "        for i, target_playlist in tqdm(enumerate(np.array(self.target_playlists))):\n",
    "\n",
    "            URM_row = self.URM[target_playlist,:] * self.S\n",
    "\n",
    "            result_tracks = self.u.get_top10_tracks(self.URM, target_playlist[0], URM_row)\n",
    "            string_rec = ' '.join(map(str, result_tracks.reshape(1, 10)[0]))\n",
    "            final_result['playlist_id'][i] = int(target_playlist)\n",
    "            if is_test:\n",
    "                final_result['track_ids'][i] = result_tracks\n",
    "            else:\n",
    "                final_result['track_ids'][i] = string_rec\n",
    "\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User_CFR(object):\n",
    "\n",
    "    def __init__(self, u):\n",
    "        self.u = u\n",
    "        self.URM = None\n",
    "        self.target_playlists = None\n",
    "        self.S = None\n",
    "\n",
    "    def fit(self, URM, target_playlists, knn, shrink, mode):\n",
    "        self.URM = URM\n",
    "        self.target_playlists = target_playlists\n",
    "        self.S = self.u.get_usersim_CF(self.URM, knn, shrink, mode)\n",
    "\n",
    "    def recommend(self, is_test):\n",
    "        print(\"Recommending\", flush=True)\n",
    "\n",
    "        final_result = pd.DataFrame(index=range(self.target_playlists.shape[0]), columns=('playlist_id', 'track_ids'))\n",
    "\n",
    "        for i, target_playlist in tqdm(enumerate(np.array(self.target_playlists))):\n",
    "\n",
    "            URM_row = self.S[target_playlist, :] * self.URM\n",
    "\n",
    "            result_tracks = self.u.get_top10_tracks(self.URM, target_playlist[0], URM_row)\n",
    "            string_rec = ' '.join(map(str, result_tracks.reshape(1, 10)[0]))\n",
    "            final_result['playlist_id'][i] = int(target_playlist)\n",
    "            if is_test:\n",
    "                final_result['track_ids'][i] = result_tracks\n",
    "            else:\n",
    "                final_result['track_ids'][i] = string_rec\n",
    "\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble_item(object):\n",
    "\n",
    "    def __init__(self, u):\n",
    "        self.u = u\n",
    "        self.S_CB = None\n",
    "        self.S_CF = None\n",
    "        self.target_playlists = None\n",
    "        self.URM = None\n",
    "\n",
    "    def fit(self, URM, target_playlists, knn1, knn2, shrink, mode):\n",
    "        self.URM = URM\n",
    "        self.target_playlists = target_playlists\n",
    "        self.S_CF = self.u.get_itemsim_CF(self.URM, knn1, shrink, mode)\n",
    "        self.S_CB = self.u.get_itemsim_CB(knn2, shrink, mode)\n",
    "\n",
    "    def recommend(self, is_test, alfa):\n",
    "        print(\"Recommending\", flush=True)\n",
    "        R_CB = self.URM * self.S_CB\n",
    "        R_CF = self.URM * self.S_CF\n",
    "        R = (alfa * R_CF) + ((1 - alfa) * R_CB)\n",
    "        final_result = pd.DataFrame(index=range(self.target_playlists.shape[0]), columns=('playlist_id', 'track_ids'))\n",
    "\n",
    "        for i, target_playlist in tqdm(enumerate(np.array(self.target_playlists))):\n",
    "            result_tracks = self.u.get_top10_tracks(self.URM, target_playlist[0], R[target_playlist[0]])\n",
    "            string_rec = ' '.join(map(str, result_tracks.reshape(1, 10)[0]))\n",
    "            final_result['playlist_id'][i] = int(target_playlist)\n",
    "            if is_test:\n",
    "                final_result['track_ids'][i] = result_tracks\n",
    "            else:\n",
    "                final_result['track_ids'][i] = string_rec\n",
    "\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid(object):\n",
    "    \n",
    "    def __init__(self, u):\n",
    "        self.u = u\n",
    "        self.S_CB = None\n",
    "        self.S_CF_item = None\n",
    "        self.S_CF_user = None\n",
    "        self.target_playlists = None\n",
    "        self.URM = None\n",
    "        \n",
    "    def fit(self, URM, target_playlists, knn1, knn2, knn3):\n",
    "        self.URM = URM\n",
    "        self.target_playlists = target_playlists\n",
    "        self.S_CF_item = self.u.get_itemsim_CF(self.URM, knn1)\n",
    "        self.S_user = self.u.get_usersim_CF(self.URM, knn2)\n",
    "        self.S_CB = self.u.get_itemsim_CB(knn3)\n",
    "        \n",
    "    def recommend(self, is_test, weights):\n",
    "        print(\"Recommending\", flush = True)\n",
    "        alfa = weights[0]\n",
    "        beta = weights[1]\n",
    "        S_item = (alfa*self.S_CF_item) + ((1-alfa)*self.S_CB)\n",
    "        R_user = self.S_user * self.URM\n",
    "        R_item = self.URM * S_item\n",
    "        R = (beta*R_item) + ((1-beta)*R_user)\n",
    "        final_result = pd.DataFrame(index=range(self.target_playlists.shape[0]), columns=('playlist_id', 'track_ids'))\n",
    "        \n",
    "        for i, target_playlist in tqdm(enumerate(np.array(self.target_playlists))):\n",
    "            result_tracks = self.u.get_top10_tracks(self.URM, target_playlist[0], R[target_playlist[0]])\n",
    "            string_rec = ' '.join(map(str, result_tracks.reshape(1, 10)[0]))\n",
    "            final_result['playlist_id'][i] = int(target_playlist)\n",
    "            if is_test:\n",
    "                final_result['track_ids'][i] = result_tracks\n",
    "            else:\n",
    "                final_result['track_ids'][i] = string_rec\n",
    "\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble_cfcb(object):\n",
    "\n",
    "    def __init__(self, u):\n",
    "        self.u = u\n",
    "        self.S_CB = None\n",
    "        self.S_CF_I = None\n",
    "        self.S_CF_U = None\n",
    "        self.target_playlists = None\n",
    "        self.URM = None\n",
    "\n",
    "    def fit(self, URM, target_playlists, knn1, knn2, knn3, shrink, mode):\n",
    "        self.URM = URM\n",
    "        self.target_playlists = target_playlists\n",
    "        self.S_CF_I = self.u.get_itemsim_CF(self.URM, knn1, shrink, mode)\n",
    "        self.S_CF_U = self.u.get_usersim_CF(self.URM, knn2, shrink, mode)\n",
    "        self.S_CB = self.u.get_itemsim_CB(knn3, shrink, mode)\n",
    "\n",
    "    def recommend(self, is_test, weights):\n",
    "        print(\"Recommending\", flush=True)\n",
    "        R_CB = self.URM * self.S_CB\n",
    "        R_CF_I = self.URM * self.S_CF_I\n",
    "        R_CF_U = self.S_CF_U * self.URM\n",
    "        R = (weights[0] * R_CF_I) + (weights[1] * R_CF_U) + (weights[2] * R_CB)\n",
    "        final_result = pd.DataFrame(index=range(self.target_playlists.shape[0]), columns=('playlist_id', 'track_ids'))\n",
    "\n",
    "        for i, target_playlist in tqdm(enumerate(np.array(self.target_playlists))):\n",
    "            result_tracks = self.u.get_top10_tracks(self.URM, target_playlist[0], R[target_playlist[0]])\n",
    "            string_rec = ' '.join(map(str, result_tracks.reshape(1, 10)[0]))\n",
    "            final_result['playlist_id'][i] = int(target_playlist)\n",
    "            if is_test:\n",
    "                final_result['track_ids'][i] = result_tracks\n",
    "            else:\n",
    "                final_result['track_ids'][i] = string_rec\n",
    "\n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlimBPRRec(object):\n",
    "    \n",
    "    def fit(self, URM, Slim, target_playlists, num_playlist_to_recommend,\n",
    "           learning_rate, epochs, positive_item_regularization,\n",
    "           negative_item_regularization, nzz, u):\n",
    "        self.URM = URM\n",
    "        self.target_playlists = target_playlists\n",
    "        self.num_playlist_to_recommend = num_playlist_to_recommend\n",
    "        self.Slim = Slim\n",
    "        self.u = u\n",
    "    \n",
    "    def recommend(self, is_test):\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        final_result = pd.DataFrame(index=range(self.target_playlists.shape[0]), columns=('playlist_id', 'track_ids'))\n",
    "        \n",
    "        print('Predicting...', flush=True)\n",
    "        for j, i in tqdm(enumerate(np.array(self.target_playlists))):\n",
    "\n",
    "            URM_row = self.URM[i,:] * self.Slim\n",
    "\n",
    "            #Make prediction\n",
    "            result_tracks = self.u.get_top10_tracks(self.URM, i[0], URM_row)\n",
    "            string_rec = ' '.join(map(str, result_tracks.reshape(1, 10)[0]))\n",
    "            final_result['playlist_id'][j] = int(i)\n",
    "            if is_test:\n",
    "                final_result['track_ids'][j] = result_tracks\n",
    "            else:\n",
    "                final_result['track_ids'][j] = string_rec\n",
    "        \n",
    "        return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train = pd.read_csv(\"../data/train.csv\")\n",
    "        self.tracks = pd.read_csv(\"../data/tracks.csv\")\n",
    "        self.target_playlists = pd.read_csv(\"../data/target_playlists.csv\")\n",
    "        self.u = Utils(self.train, self.tracks, self.target_playlists)\n",
    "        self.e = Eval(self.u)\n",
    "        self.URM_full = self.u.get_URM()\n",
    "        self.URM_train = self.e.get_URM_train()\n",
    "\n",
    "\n",
    "    def recommend_itemCBR(self, is_test, knn=300, shrink=300, mode='cosine'):\n",
    "        rec = Item_CBR(self.u)\n",
    "        if is_test:\n",
    "            target_playlists = self.e.get_target_playlists()\n",
    "            rec.fit(self.URM_train, target_playlists, knn, shrink, mode)\n",
    "            result = rec.recommend(True)\n",
    "            self.e.MAP(result, self.e.get_target_tracks())\n",
    "        else:\n",
    "            target = self.u.get_target_playlists()\n",
    "            rec.fit(self.URM_full, target, knn, shrink, mode)\n",
    "            result = rec.recommend(False)\n",
    "            result.to_csv(\"predictions/item_cbr.csv\", index=False)\n",
    "\n",
    "\n",
    "    def recommend_itemCFR(self, is_test, knn=400, shrink=300, mode='cosine'):\n",
    "        rec = Item_CFR(self.u)\n",
    "        if is_test:\n",
    "            target_playlists = self.e.get_target_playlists()\n",
    "            rec.fit(self.URM_train, target_playlists, knn, shrink, mode)\n",
    "            result = rec.recommend(True)\n",
    "            self.e.MAP(result, self.e.get_target_tracks())\n",
    "        else:\n",
    "            target = self.u.get_target_playlists()\n",
    "            rec.fit(self.URM_full, target, knn, shrink, mode)\n",
    "            result = rec.recommend(False)\n",
    "            result.to_csv(\"predictions/item_cfr.csv\", index=False)\n",
    "\n",
    "\n",
    "    def recommend_userCFR(self, is_test, knn=400, shrink=300, mode='cosine'):\n",
    "        rec = User_CFR(self.u)\n",
    "        if is_test:\n",
    "            target_playlists = self.e.get_target_playlists()\n",
    "            rec.fit(self.URM_train, target_playlists, knn, shrink, mode)\n",
    "            result = rec.recommend(True)\n",
    "            self.e.MAP(result, self.e.get_target_tracks())\n",
    "        else:\n",
    "            target = self.u.get_target_playlists()\n",
    "            rec.fit(self.URM_full, target, knn, shrink, mode)\n",
    "            result = rec.recommend(False)\n",
    "            result.to_csv(\"../predictions/user_cfr.csv\", index=False)\n",
    "\n",
    "    def recommend_ensemble_item(self, is_test, alfa=0.7, knn1=400, knn2=400, shrink=300, mode='cosine'):\n",
    "        rec = Ensemble_item(self.u)\n",
    "        if is_test:\n",
    "            target_playlists = self.e.get_target_playlists()\n",
    "            rec.fit(self.URM_train, target_playlists, knn1, knn2, shrink, mode)\n",
    "            result = rec.recommend(True, alfa)\n",
    "            self.e.MAP(result, self.e.get_target_tracks())\n",
    "        else:\n",
    "            target = self.u.get_target_playlists()\n",
    "            rec.fit(self.URM_full, target, knn1, knn2, shrink, mode)\n",
    "            result = rec.recommend(False, alfa)\n",
    "            result.to_csv(\"../predictions/item_avg.csv\", index=False)\n",
    "\n",
    "    def recommend_ensemble_cfcb(self, is_test, weights=[0.6, 0.4, 0.5], knn1=400, knn2=400, knn3=300, shrink=300, mode='cosine'):\n",
    "        rec = Ensemble_cfcb(self.u)\n",
    "        if is_test:\n",
    "            target_playlists = self.e.get_target_playlists()\n",
    "            rec.fit(self.URM_train, target_playlists, knn1, knn2, knn3, shrink, mode)\n",
    "            result = rec.recommend(True, weights)\n",
    "            self.e.MAP(result, self.e.get_target_tracks())\n",
    "        else:\n",
    "            target = self.u.get_target_playlists()\n",
    "            rec.fit(self.URM_full, target, knn1, knn2, knn3, shrink, mode)\n",
    "            result = rec.recommend(False, weights)\n",
    "            result.to_csv(\"../predictions/ensemble1.csv\", index=False)\n",
    "\n",
    "    def recommend_hybrid(self, is_test, weights=[0.7, 0.65], knn1=400, knn2=400, knn3=300, shrink=300, mode='cosine'):\n",
    "        rec = Hybrid(self.u)\n",
    "        if is_test:\n",
    "            target_playlists = self.e.get_target_playlists()\n",
    "            rec.fit(self.URM_train, target_playlists, knn1, knn2, knn3, shrink, mode)\n",
    "            result = rec.recommend(True, weights)\n",
    "            self.e.MAP(result, self.e.get_target_tracks())\n",
    "        else:\n",
    "            target = self.u.get_target_playlists()\n",
    "            rec.fit(self.URM_full, target, knn1, knn2, knn3, shrink, mode)\n",
    "            result = rec.recommend(False, weights)\n",
    "            result.to_csv(\"../predictions/hybrid.csv\", index=False)\n",
    "\n",
    "    def recommend_slimBPR(self, is_test, knn=100, shrink=300, mode='cosine'):\n",
    "        rec = SlimBPRRec()\n",
    "        if is_test:\n",
    "            BPR_gen = SlimBPR(self.URM_train)\n",
    "            S_bpr = BPR_gen.get_S_SLIM_BPR(knn, shrink, mode)\n",
    "            target_playlists = self.e.get_target_playlists()\n",
    "            rec.fit(self.URM_train, S_bpr, target_playlists, 10000,\n",
    "                    learning_rate=0.1, epochs=1, positive_item_regularization=1.0,\n",
    "                    negative_item_regularization=1.0, nzz=1, u=self.u)\n",
    "            result = rec.recommend(True)\n",
    "            self.e.MAP(result, self.e.get_target_tracks())\n",
    "        else:\n",
    "            BPR_gen = SlimBPR(self.URM_full)\n",
    "            S_bpr = BPR_gen.get_S_SLIM_BPR(knn, shrink, mode)\n",
    "            target = self.u.get_target_playlists()\n",
    "            rec.fit(self.URM_full, S_bpr, target, 10000,\n",
    "                    learning_rate=0.1, epochs=1, positive_item_regularization=1.0,\n",
    "                    negative_item_regularization=1.0, nzz=1, u=self.u)\n",
    "            result = rec.recommend(False)\n",
    "            result.to_csv(\"../predictions/slimBPR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = Recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 20635 ( 100 % ), 1935.58 column/sec, elapsed time 0.18 min\n",
      "Recommending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5261it [00:54, 92.41it/s] "
     ]
    }
   ],
   "source": [
    "run.recommend_itemCBR(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
